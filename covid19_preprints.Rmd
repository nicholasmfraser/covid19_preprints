---
title: "R Notebook"
---

# Load packages 

```{r}

library(tidyverse)
library(rcrossref)
library(lubridate)
library(aRxiv)

```

# Crossref data

```{r}

# Retrieve details of all preprints posted to Crossref from 2020-01-01 until
# today. Use the low-level cr_types_ function from rcrossref to return all
# associated metadata in list format
cr_p <- cr_types_(types = "posted-content",
                  works = TRUE, 
                  filter = c(from_posted_date = "2020-01-01", 
                  until_posted_date = as.character(Sys.Date())), 
                  limit = 1000, 
                  cursor = "*",
                  parse = TRUE,
                  cursor_max = 100000)

```

```{r}

# Function for parsing posted dates from crossref metadata
parsePostedDate <- function(item) {
  if(length(item$posted$`date-parts`[[1]]) == 3) {
    return(ymd(str_c(item$posted$`date-parts`[[1]][[1]], "-",
                     item$posted$`date-parts`[[1]][[2]], "-",
                     item$posted$`date-parts`[[1]][[3]])))
  } else {
    return(NA)
  }
}

# Parse relevant fields into dataframe. Keep the 'institution', 'publisher' and
# 'group-title' fields - these are useful later for matching items to preprint
# repositories
parsePreprints <- function(item) {
  tibble(
    institution = if(length(item$institution$name)) item$institution$name else NA,
    publisher = item$publisher,
    group_title = if(length(item$`group-title`)) item$`group-title` else NA,
    cr_member_id = item$member,
    doi = item$DOI,
    title = item$title[[1]],
    posted_date = parsePostedDate(item),
    abstract = if(length(item$abstract)) item$abstract else NA
  )
}

# Parse preprints info to a dataframe
cr_p_df <- map_dfr(cr_p, function(x) 
                         map_dfr(x$message$items, function(y)
                                                  parsePreprints(y)))

```

```{r}

# Generate a search string containing terms related to COVID-19
search_string <- "coronavirus|covid-19|sars-cov|ncov-2019|2019-ncov"

# Subset preprints which mention COVID-19 related terms in title or abstract 
cr_covid <- cr_p_df %>%
  filter(str_detect(title, regex(search_string, ignore_case = TRUE)) | 
         str_detect(abstract, regex(search_string, ignore_case = TRUE))) %>%
  # Rule-based matching of preprints to repositories. For CSHL repositories, the
  # repository name (bioRxiv/medRxiv) is contained in the 'institution' field. For
  # others we can use the 'publisher' field, except for any preprint servers 
  # hosted on OSF in which we should use the 'group_title' field to ensure we get
  # the right repository.
  mutate(source = case_when(
    institution == "bioRxiv" ~ "bioRxiv",
    institution == "medRxiv" ~ "medRxiv",
    publisher == "Research Square" ~ "Research Square",
    publisher == "MDPI AG" ~ "Preprints.org",
    publisher == "American Chemical Society (ACS)" ~ "ChemRxiv",
    publisher == "JMIR Publications Inc." ~ "JMIR",
    publisher == "WHO Press" ~ "WHO",
    publisher == "ScienceOpen" ~ "ScienceOpen",
    publisher == "SAGE Publications" ~ "SAGE",
    group_title == "PsyArXiv" ~ "PsyArXiv (OSF)",
    group_title == "NutriXiv" ~ "NutriXiv (OSF)",
    group_title == "SocArXiv" ~ "SocArXiv (OSF)",
    group_title == "EdArXiv" ~ "EdArXiv (OSF)",
    group_title == "MediArXiv" ~ "MediArXiv (OSF)",
    group_title == "AfricArXiv" ~ "AfricArXiv (OSF)",
    group_title == "EarthArXiv" ~ "EarthArXiv (OSF)",
    group_title == "IndiaRxiv" ~ "IndiaRxiv (OSF)",
    group_title == "EcoEvoRxiv" ~ "EcoEvoRxiv (OSF)",
    group_title == "Open Science Framework" ~ "OSF Preprints"
  )) %>%
  # Remove those that could not be unambiguously matched
  filter(!is.na(source)) %>%
  # Some preprints have multiple DOI records relating to multiple preprint
  # versions (mainly in ChemRxiv and Preprints.org). In these cases the DOI 
  # is usually appended with a version number, e.g. 10.1000/12345.v2. To ensure
  # only a single record is counted per preprint, the version number is
  # removed and only the earliest DOI record is kept
  mutate(doi_clean = str_replace(doi, "\\.v.*|\\/v.*", "")) %>%
  group_by(doi_clean) %>%
  arrange(posted_date) %>%
  slice(1) %>%
  ungroup() %>%
  # Additionally filter preprints with the same title posted on the same server
  group_by(source, title) %>%
  arrange(posted_date) %>%
  slice(1) %>%
  ungroup() %>%
  # Select only relevant fields with unique values
  select(source, doi, posted_date, title, abstract) %>%
  distinct()

```

# arXiv data

```{r}

# For returning details of preprints on arXiv, we can use the aRxiv package and
# define title and abstract search strings
ar_covid <- arxiv_search('ti:coronavirus OR ti:covid-19 OR ti:sars-cov OR ti:ncov-2019 OR ti:2019-ncov OR abs:coronavirus OR abs:covid-19 OR abs:sars-cov OR abs:ncov-2019 OR abs:2019-ncov', limit=10000) %>% 
  mutate(source = "arXiv",
         arxiv_id = id,
         posted_date = as_date(submitted)) %>%
  filter(posted_date >= ymd("2020-01-01")) %>%
  select(source, arxiv_id, posted_date, title, abstract) %>%
  distinct()

```

# Create final dataset (bind Crossref and arXiv data)

```{r}

sample_date <- "2020-04-05"

covid_preprints <- bind_rows(cr_covid, ar_covid) %>%
  select(source, doi, arxiv_id, posted_date, title, abstract) %>%
  mutate(posted_date = as_date(posted_date)) %>%
  filter(posted_date <= ymd(sample_date))

covid_preprints %>%
  write_csv("data/covid19_preprints.csv")

```

# Visualizations

```{r}

# Daily preprint counts
covid_preprints %>%
  count(source, posted_date) %>%
  ggplot(aes(x = posted_date, y = n, fill = source)) +
  geom_col(color = "#ffffff", size = 0.25) +
  labs(x = "Posted Date", y = "Preprints", fill = "Source",
       title = "COVID-19 preprints per day",
       subtitle = paste0("(up until ", sample_date, ")")) +
  scale_x_date(date_breaks = "7 days",
               date_minor_breaks = "1 day",
               expand = c(0.01, 0),
               limits = c(ymd("2020-01-15"), ymd(sample_date)+1)) +
  theme_minimal() +
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 90, vjust = 0.5),
        axis.title.x = element_text(margin = margin(20, 0, 0, 0)),
        axis.title.y = element_text(margin = margin(0, 20, 0, 0)),
        legend.key.size = unit(0.5, "cm"),
        legend.text=element_text(size = 8)) +
  ggsave("outputs/figures/covid19_preprints_day.png", width = 12, height = 6)

# Weekly preprint counts
covid_preprints %>%
  mutate(posted_week = as.Date(cut(posted_date,
                                   breaks = "week",
                                   start.on.monday = TRUE))) %>%
  count(source, posted_week) %>%
  ggplot(aes(x = posted_week, y = n, fill = source)) +
  geom_col(color = "#ffffff", size = 0.25) +
  labs(x = "Posted Date (by week)", y = "Preprints", fill = "Source",
       title = "COVID-19 preprints per week", 
       subtitle = paste0("(up until ", sample_date, ")")) +
  scale_x_date(date_breaks = "1 week",
               expand = c(0.01, 0),
               limits = c(ymd("2020-01-13"), ymd(sample_date))) +
  theme_minimal() +
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 90, vjust = 0.5),
        axis.title.x = element_text(margin = margin(20, 0, 0, 0)),
        axis.title.y = element_text(margin = margin(0, 20, 0, 0)),
        legend.key.size = unit(0.5, "cm"),
        legend.text=element_text(size = 8)) +
  ggsave("outputs/figures/covid19_preprints_week.png", width = 12, height = 6)

```




